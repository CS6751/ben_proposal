\documentclass[10pt]{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\begin{document}

\section{Overview} \label{sec:overview}
\subsection*{Project Summary}
\par Clamps and "helping hands" are critical tools for skilled, dextrous work. They hold working items like circuit boards steady in a useful position. This seems like an obvious task for a robot - more flexible and user friendly than a purely mechanical solution, but stronger and more tireless than a human assistant. However, the task - holding items to aid dextrous work - has two components which often contradict one another: the grip needs to hold the object rigidly, but also compliant when necessary. At the same time, it is constrained to avoid certain areas that may be delicate, or in the way of the human. This project will tackle the problem of robotic gripping under constraints.
\par The goal of this project is to create a robotic system that:
\begin{itemize}


\item Perceives an item to be held
\item Accepts human commands to grasp, let go, etc.
\item Grasps that item while attempting to maintain the item's pose
\item Grasps the item while obeying constraints
\item Exhibits compliant behavior that allows the human to re-position the item 
\item Exhibits rigid behavior to keep the item steady during work
\end{itemize}

\subsection*{Perception Component}
This component of the system collect and analyze visual input from the workspace.
\par \textbf{Inputs} RGBD data from one or more kinect sensors mounted above the workspace. Human inputs filtered through the human interaction module.
\par \textbf{Outputs} A conservative convex hull of the human arm. An estimate on the object's pose. The position of the human finger and where it's pointing. A list of suggested grips, rated by quality.  
\par \textbf{Challenges} The problems that perception will tackle:
\begin{itemize}
\item Identifying the target object
\item Distinguishing the human hand (so the robot avoids it)
\item Distinguishing the item's pose in 6-dof (so the robot can attempt to match it)
\item Identifying and evaluating a potential grip candidates
\item Identifying the human finger and where it is pointing and incorporating that into grip ratings
\item Identifying areas to avoid
\end{itemize}

\section{Research Contribution} \label{sec:contribution}

The research contribution goal will be to outline methods of perceiving grasp constraints and evaluating potential grasps under those constraints. 

\section{Approach} \label{sec:approach}


%Most approaches to grasping assume that the target item is sitting on a surface and can be grabbed anywhere. They use a plethora of methods to create a potential grasp, whether it is scanning the object and calculating force closure, learning from previous grasps/human graps, or acting off of image features and machine learning. None of these methods place requirements on the item itself. However, most useful robotics take advantage of regularization of an environment. Humans are excellent at evaluating grasps, so why not meet partway and have the human suggest a grasp by marking two small dots on the item where it would be useful to pinch? This strategy might be considered 'cheating', but it may allow for faster and better grasping with little extra human effort. In the future, there's no reason why items couldn't be marked up to suggest robot grips inconspicuously with tags that are invisible to the human eye. 

The perception module will start with the basic tasks of identifying the object and the human, identifying potential grips based using machine learning with cubes of voxels as features . The next level will add constraints on the grips - clearly marking the areas on the board that are "better" and "worse" with painted tape. The two stretch goals will be to guess for where the human is pointing and actually learn to identify fragile features, incorporating them into grip selection.
 
 \textbf{Possible Addition} Integrating human feedback could be an additional novel part of the project. It's often clear to us which grip is good and strong and which one is terrible. Commands like "too loose" could reset the estimation of the grasp and, going even further, commands like "shift up a little" could modify the seed for the estimator.
 
 \subsection{Actual tasks}
 \begin{enumerate}
 \item Write out the structure of the neural network for the learning algorithm
 \item Create an image library of rgbd views of items with marks held by a human hand
 \item Find the bounding box for the human hand/arm in the images
 \item Estimate the pose of the item in the image (take 3 surface features, track them and create body axes with them to define a pose)
 \item Divide images into features 
 \item Do offline testing to assign weights to features
 \item Idenfiy vector associated with human finger and incorporate into grip selection
 \item Learn to identify "bad" areas of the surface based first on markers and then on raw RGBD data

\end{enumerate} 
\nocite{*} 
\bibliographystyle{plain} 
\bibliography{references.bib}

 



\end{document}
